Audio-Video Deepfake Detection

Overview
Audio-Video Deepfake Detection is a full-stack AI application that leverages deep learning models to detect deepfakes in both audio and video files. The project features a modern web interface and robust backend, allowing users to upload media and receive deepfake detection results in real time.

Features
ğŸ¥ Video deepfake detection using ResNet50
ğŸ¤ Audio deepfake detection using VGG16+LSTM
ğŸŒ Web frontend (React or Streamlit)
ğŸ“Š Confidence scores and result dashboard
ğŸ—‚ï¸ Detection history (optional)
ğŸ”’ User authentication (optional)
ğŸš€ Easy deployment (Docker, Railway, Render)
â˜ï¸ Model weights hosted on Hugging Face Hub for easy access and portability

Model Information

Video Model: ResNet50 trained for deepfake detection.
Audio Model: VGG16 + LSTM trained for audio deepfake detection.
Model Hosting: All models are stored and loaded from Hugging Face Hub for reliability and portability.
Custom Loss: Focal Loss for imbalanced data.

Model Weights & Hugging Face Integration

Model Storage
All trained model weights are hosted on the Hugging Face Hub for reliable, versioned, and fast downloads.
Repository: https://huggingface.co/nagashreens05/deepguard/tree/main1

final_faceforensics_resnet50.keras
final_model.keras
final_resnet50_deepfake.keras

How Models Are Loaded
The backend code references these models directly from Hugging Face using the Keras-Hugging Face integration:

python
import keras
# Example: load a model hosted on Hugging Face
model = keras.saving.load_model("hf://nagashreens05/deepguard/final_resnet50_deepfake.keras")
This requires the huggingface_hub and a recent version of keras (pip install -U keras huggingface_hub).

No need to manually download or store large model files in your repository or Docker image.
See the Hugging Face documentation for more details.

Project Structure

Audio-Video_Deepfake-Detection/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

Setup & Installation

Backend (FastAPI)

Clone the repository:
git clone https://github.com/Nagashree05/Audio-Video_Deepfake-Detection.git
cd Audio-Video_Deepfake-Detection/backend

Create and activate a virtual environment:
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

Install dependencies:
pip install --upgrade pip
pip install -r requirements.txt

Run the backend server:
uvicorn app.main:app --reload

Frontend (React)

Navigate to the frontend directory:
cd ../frontend

Install frontend dependencies:
npm install

Start the frontend development server:
npm run dev

Usage

Open the frontend in your browser (http://localhost:3000 or Streamlit URL).
Upload a video or audio file.
View the detection result and confidence score.

Deployment

Docker

Build the Docker image:
docker build -t deepfake-backend ./backend
Run the container:
docker run -p 8000:8000 deepfake-backend

Railway/Render

Set the root directory to backend.
Use the Dockerfile provided.
Set the start command to:
uvicorn app.main:app --host 0.0.0.0 --port $PORT

Models will be automatically downloaded from Hugging Face at runtime.

Troubleshooting
ModuleNotFoundError: Ensure your working directory and import paths are correct.
Model file not found: Check Hugging Face model path and your internet connection.
CORS errors: Make sure CORS is enabled in your FastAPI backend.
TensorFlow warnings: These are informational; for CPU-only environments, they can be ignored.

License
This project is licensed under the MIT License.